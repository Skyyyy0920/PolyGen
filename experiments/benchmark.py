#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸åŸå§‹PolyGen-F06Cçš„å¯¹æ¯”å®éªŒ

å®ç°å®Œæ•´çš„åŸºå‡†æµ‹è¯•ï¼Œå¯¹æ¯”åŒç”Ÿæˆå™¨æ–¹æ³•ä¸åŸå§‹æ–¹æ³•çš„æ€§èƒ½
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader

# å¯¼å…¥åŸå§‹PolyGen-F06Cæ¨¡å—
sys.path.append(str(Path(__file__).parent.parent.parent / "PolyGen-F06C"))
try:
    from data.dataset import ChainSetDataset, collate_fn_set_transformer
    from data.block_dist import mayo_lewis_from_sequence
    from src.encoder import ConditionEncoder as OriginalConditionEncoder
    from src.diffusion import DiT1D, NoiseSchedule as OriginalNoiseSchedule, ddim_sample, hist_to_logits, logits_to_hist
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥åŸå§‹PolyGen-F06Cæ¨¡å—: {e}")
    print("è¯·ç¡®ä¿PolyGen-F06Cç›®å½•å­˜åœ¨ä¸”åŒ…å«å¿…è¦æ–‡ä»¶")

# å¯¼å…¥åŒç”Ÿæˆå™¨æ¨¡å—
from ..models.dual_generator import DualGeneratorModel
from ..data.dataset import DualPolyDataset, collate_dual_poly
from ..training.utils import EvaluationMetrics


@dataclass
class BenchmarkConfig:
    """åŸºå‡†æµ‹è¯•é…ç½®"""
    # æ•°æ®é…ç½®
    csv_path: str = "PolyGen-F06C/data/copolymer.csv"
    max_samples: Optional[int] = 1000
    test_ratio: float = 0.2
    batch_size: int = 8
    
    # æ¨¡å‹é…ç½®
    bins: int = 50
    
    # åŸå§‹æ¨¡å‹é…ç½®
    original_cond_ckpt: Optional[str] = None
    original_diffusion_ckpt: Optional[str] = None
    
    # åŒç”Ÿæˆå™¨é…ç½®
    dual_model_ckpt: Optional[str] = None
    
    # è¯„ä¼°é…ç½®
    num_inference_steps: int = 50
    guidance_scale: float = 1.0
    temperature: float = 1.0
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "outputs/benchmark_comparison"
    save_visualizations: bool = True
    num_visualization_samples: int = 12


class PolyGenComparison:
    """PolyGenå¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self, config: BenchmarkConfig):
        """
        åˆå§‹åŒ–å¯¹æ¯”å®éªŒ
        
        Args:
            config: åŸºå‡†æµ‹è¯•é…ç½®
        """
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜é…ç½®
        with open(self.output_dir / "benchmark_config.json", 'w') as f:
            json.dump(config.__dict__, f, indent=2)
        
        # åˆå§‹åŒ–è¯„ä¼°å™¨
        self.evaluator = EvaluationMetrics()
        
        # åŠ è½½æ•°æ®
        self.test_loader = self._load_test_data()
        
        print(f"ğŸ”¬ PolyGenå¯¹æ¯”å®éªŒåˆå§‹åŒ–å®Œæˆ")
        print(f"  è®¾å¤‡: {self.device}")
        print(f"  æµ‹è¯•æ ·æœ¬æ•°: {len(self.test_loader.dataset)}")
        print(f"  è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def _load_test_data(self) -> DataLoader:
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        print("ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®...")
        
        # ä½¿ç”¨åŒç”Ÿæˆå™¨æ•°æ®é›†æ ¼å¼
        test_dataset = DualPolyDataset(
            csv_path=self.config.csv_path,
            max_length=self.config.bins,
            max_samples=self.config.max_samples,
            split='test',
            test_ratio=self.config.test_ratio
        )
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            collate_fn=collate_dual_poly,
            num_workers=0
        )
        
        return test_loader
    
    def load_original_model(self) -> Optional[Tuple]:
        """
        åŠ è½½åŸå§‹PolyGen-F06Cæ¨¡å‹
        
        Returns:
            (condition_encoder, diffusion_model, noise_schedule) æˆ– None
        """
        if not self.config.original_cond_ckpt or not self.config.original_diffusion_ckpt:
            print("âš ï¸ æœªæä¾›åŸå§‹æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼Œè·³è¿‡åŸå§‹æ¨¡å‹è¯„ä¼°")
            return None
        
        try:
            print("ğŸ”§ åŠ è½½åŸå§‹PolyGen-F06Cæ¨¡å‹...")
            
            # åŠ è½½æ¡ä»¶ç¼–ç å™¨
            cond_ckpt = torch.load(self.config.original_cond_ckpt, map_location=self.device, weights_only=False)
            cond_args = cond_ckpt.get("args", {})
            
            condition_encoder = OriginalConditionEncoder(
                in_dim=int(cond_args.get("cond_in_dim", 17)),
                d_model=int(cond_args.get("d_model", 128)),
                proj_dim=int(cond_args.get("proj_dim", 256)),
                num_layers=int(cond_args.get("num_layers", 3)),
                dropout=cond_args.get("dropout", 0.1),
                temperature=float(cond_args.get("temperature", 0.10)),
            ).to(self.device)
            
            condition_encoder.load_state_dict(cond_ckpt["model"], strict=False)
            condition_encoder.eval()
            
            # åŠ è½½æ‰©æ•£æ¨¡å‹
            diffusion_ckpt = torch.load(self.config.original_diffusion_ckpt, map_location=self.device, weights_only=False)
            diffusion_args = diffusion_ckpt.get("args", {})
            
            diffusion_model = DiT1D(
                bins=self.config.bins,
                cond_dim=int(cond_args.get("d_model", 128)),
                d_model=int(diffusion_args.get("dit_d_model", 256)),
                n_layers=int(diffusion_args.get("dit_layers", 8)),
                n_heads=int(diffusion_args.get("dit_heads", 8)),
                dropout=diffusion_args.get("dropout", 0.1),
                film_each_layer=diffusion_args.get("film_each_layer", True)
            ).to(self.device)
            
            diffusion_model.load_state_dict(diffusion_ckpt["model"], strict=False)
            diffusion_model.eval()
            
            # å™ªå£°è°ƒåº¦å™¨
            noise_schedule = OriginalNoiseSchedule(
                T=int(diffusion_args.get("T", 1000))
            ).to(self.device)
            
            print("âœ… åŸå§‹æ¨¡å‹åŠ è½½å®Œæˆ")
            return condition_encoder, diffusion_model, noise_schedule
            
        except Exception as e:
            print(f"âŒ åŠ è½½åŸå§‹æ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def load_dual_generator_model(self) -> Optional[DualGeneratorModel]:
        """
        åŠ è½½åŒç”Ÿæˆå™¨æ¨¡å‹
        
        Returns:
            DualGeneratorModel æˆ– None
        """
        if not self.config.dual_model_ckpt:
            print("âš ï¸ æœªæä¾›åŒç”Ÿæˆå™¨æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼Œè·³è¿‡åŒç”Ÿæˆå™¨è¯„ä¼°")
            return None
        
        try:
            print("ğŸ”§ åŠ è½½åŒç”Ÿæˆå™¨æ¨¡å‹...")
            
            checkpoint = torch.load(self.config.dual_model_ckpt, map_location=self.device, weights_only=False)
            
            # ä»æ£€æŸ¥ç‚¹è·å–é…ç½®
            model_config = checkpoint.get("config", {})
            
            # åˆ›å»ºæ¨¡å‹
            dual_model = DualGeneratorModel(
                bins=self.config.bins,
                condition_dim=model_config.get("condition_dim", 17),
                cond_encoder_d_model=model_config.get("cond_encoder_d_model", 128),
                residual_hidden_size=model_config.get("residual_hidden_size", 256),
                residual_num_layers=model_config.get("residual_num_layers", 8),
                diffusion_steps=model_config.get("diffusion_steps", 1000)
            ).to(self.device)
            
            # åŠ è½½æƒé‡
            dual_model.load_state_dict(checkpoint["model_state_dict"])
            dual_model.eval()
            
            print("âœ… åŒç”Ÿæˆå™¨æ¨¡å‹åŠ è½½å®Œæˆ")
            return dual_model
            
        except Exception as e:
            print(f"âŒ åŠ è½½åŒç”Ÿæˆå™¨æ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def evaluate_original_model(self, original_models: Tuple) -> Dict[str, any]:
        """
        è¯„ä¼°åŸå§‹PolyGen-F06Cæ¨¡å‹
        
        Args:
            original_models: (condition_encoder, diffusion_model, noise_schedule)
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        condition_encoder, diffusion_model, noise_schedule = original_models
        
        print("ğŸ“Š è¯„ä¼°åŸå§‹PolyGen-F06Cæ¨¡å‹...")
        
        all_predictions = []
        all_targets = []
        all_theoretical = []
        all_mayo_params = []
        
        inference_times = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(self.test_loader):
                condition_features = batch['condition_features'].to(self.device)
                block_distributions = batch['block_distributions'].to(self.device)
                sequences_batch = batch['sequences']
                
                batch_size = condition_features.size(0)
                
                start_time = time.time()
                
                # æ¡ä»¶ç¼–ç 
                cond_results = condition_encoder(cond=condition_features)
                cond_emb = cond_results["cond_emb"]
                
                # DDIMé‡‡æ ·
                z0, _ = ddim_sample(
                    model=diffusion_model,
                    cond=cond_emb,
                    schedule=noise_schedule,
                    steps=self.config.num_inference_steps,
                    guidance=None,
                    bins=self.config.bins,
                    tau=self.config.temperature
                )
                
                # è½¬æ¢ä¸ºåˆ†å¸ƒ
                predictions = logits_to_hist(z0, tau=self.config.temperature)
                
                inference_time = time.time() - start_time
                inference_times.append(inference_time / batch_size)  # æ¯ä¸ªæ ·æœ¬çš„æ—¶é—´
                
                # è®¡ç®—Mayo-Lewisç†è®ºåˆ†å¸ƒ
                theoretical_dists = []
                mayo_params = []
                for sequences in sequences_batch:
                    theo_dist = mayo_lewis_from_sequence(sequences, max_length=self.config.bins)
                    theoretical_dists.append(theo_dist)
                    
                    # æå–Mayo-Lewiså‚æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                    all_seq = ''.join(sequences)
                    f_A = all_seq.count('A') / len(all_seq) if all_seq else 0.5
                    mayo_params.append({'f_A': f_A})
                
                theoretical_dists = torch.tensor(np.stack(theoretical_dists), dtype=torch.float32)
                
                # æ”¶é›†ç»“æœ
                all_predictions.append(predictions.cpu().numpy())
                all_targets.append(block_distributions.cpu().numpy())
                all_theoretical.append(theoretical_dists.numpy())
                all_mayo_params.extend(mayo_params)
                
                if batch_idx % 10 == 0:
                    print(f"  å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{len(self.test_loader)}")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_predictions = np.concatenate(all_predictions, axis=0)
        all_targets = np.concatenate(all_targets, axis=0)
        all_theoretical = np.concatenate(all_theoretical, axis=0)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = self.evaluator.compute_metrics(all_predictions, all_targets)
        mayo_comparison = self.evaluator.compute_mayo_lewis_comparison(
            all_predictions, all_targets, all_theoretical
        )
        
        # æ€§èƒ½ç»Ÿè®¡
        avg_inference_time = np.mean(inference_times)
        
        results = {
            'model_type': 'PolyGen-F06C Original',
            'metrics': metrics,
            'mayo_lewis_comparison': mayo_comparison,
            'performance': {
                'avg_inference_time_per_sample': avg_inference_time,
                'total_samples': len(all_predictions)
            },
            'predictions': all_predictions,
            'targets': all_targets,
            'theoretical': all_theoretical,
            'mayo_parameters': all_mayo_params
        }
        
        print(f"âœ… åŸå§‹æ¨¡å‹è¯„ä¼°å®Œæˆ")
        print(f"  KLæ•£åº¦: {metrics['kl_divergence']:.6f}")
        print(f"  EMD: {metrics['earth_mover_distance']:.6f}")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.4f}s/æ ·æœ¬")
        
        return results
    
    def evaluate_dual_generator(self, dual_model: DualGeneratorModel) -> Dict[str, any]:
        """
        è¯„ä¼°åŒç”Ÿæˆå™¨æ¨¡å‹
        
        Args:
            dual_model: åŒç”Ÿæˆå™¨æ¨¡å‹
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print("ğŸ“Š è¯„ä¼°åŒç”Ÿæˆå™¨æ¨¡å‹...")
        
        all_predictions = []
        all_targets = []
        all_theoretical = []
        all_residual_corrected = []
        all_confidences = []
        all_quality_scores = []
        all_mayo_params = []
        
        inference_times = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(self.test_loader):
                condition_features = batch['condition_features'].to(self.device)
                block_distributions = batch['block_distributions'].to(self.device)
                sequences_batch = batch['sequences']
                
                batch_size = condition_features.size(0)
                
                start_time = time.time()
                
                # æ¨ç†
                results = dual_model(
                    condition_features=condition_features,
                    sequences_batch=sequences_batch,
                    mode='inference',
                    num_steps=self.config.num_inference_steps,
                    guidance_scale=self.config.guidance_scale,
                    temperature=self.config.temperature,
                    fusion_strategy='adaptive'
                )
                
                inference_time = time.time() - start_time
                inference_times.append(inference_time / batch_size)
                
                # æ”¶é›†ç»“æœ
                all_predictions.append(results['fused_distribution'].cpu().numpy())
                all_targets.append(block_distributions.cpu().numpy())
                all_theoretical.append(results['theoretical_distributions'].cpu().numpy())
                all_residual_corrected.append(results['residual_corrected_distributions'].cpu().numpy())
                all_confidences.append(results['confidence'].cpu().numpy())
                all_quality_scores.append(results['quality_score'].cpu().numpy())
                all_mayo_params.extend(results['mayo_parameters'])
                
                if batch_idx % 10 == 0:
                    print(f"  å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{len(self.test_loader)}")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_predictions = np.concatenate(all_predictions, axis=0)
        all_targets = np.concatenate(all_targets, axis=0)
        all_theoretical = np.concatenate(all_theoretical, axis=0)
        all_residual_corrected = np.concatenate(all_residual_corrected, axis=0)
        all_confidences = np.concatenate(all_confidences, axis=0)
        all_quality_scores = np.concatenate(all_quality_scores, axis=0)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = self.evaluator.compute_metrics(all_predictions, all_targets)
        mayo_comparison = self.evaluator.compute_mayo_lewis_comparison(
            all_predictions, all_targets, all_theoretical
        )
        
        # æ€§èƒ½ç»Ÿè®¡
        avg_inference_time = np.mean(inference_times)
        
        results = {
            'model_type': 'DualGenerator',
            'metrics': metrics,
            'mayo_lewis_comparison': mayo_comparison,
            'performance': {
                'avg_inference_time_per_sample': avg_inference_time,
                'total_samples': len(all_predictions)
            },
            'predictions': all_predictions,
            'targets': all_targets,
            'theoretical': all_theoretical,
            'residual_corrected': all_residual_corrected,
            'confidences': all_confidences,
            'quality_scores': all_quality_scores,
            'mayo_parameters': all_mayo_params,
            'dual_generator_specific': {
                'avg_confidence': float(np.mean(all_confidences)),
                'avg_quality_score': float(np.mean(all_quality_scores)),
                'confidence_std': float(np.std(all_confidences)),
                'quality_score_std': float(np.std(all_quality_scores))
            }
        }
        
        print(f"âœ… åŒç”Ÿæˆå™¨è¯„ä¼°å®Œæˆ")
        print(f"  KLæ•£åº¦: {metrics['kl_divergence']:.6f}")
        print(f"  EMD: {metrics['earth_mover_distance']:.6f}")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.4f}s/æ ·æœ¬")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {np.mean(all_confidences):.3f}")
        print(f"  å¹³å‡è´¨é‡è¯„åˆ†: {np.mean(all_quality_scores):.3f}")
        
        return results
    
    def run_comparison(self) -> Dict[str, any]:
        """
        è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
        
        Returns:
            å¯¹æ¯”ç»“æœå­—å…¸
        """
        print(f"ğŸš€ å¼€å§‹PolyGenå¯¹æ¯”å®éªŒ...")
        
        comparison_results = {
            'config': self.config.__dict__,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'device': str(self.device),
            'results': {}
        }
        
        # è¯„ä¼°åŸå§‹æ¨¡å‹
        original_models = self.load_original_model()
        if original_models is not None:
            original_results = self.evaluate_original_model(original_models)
            comparison_results['results']['original'] = original_results
        
        # è¯„ä¼°åŒç”Ÿæˆå™¨æ¨¡å‹
        dual_model = self.load_dual_generator_model()
        if dual_model is not None:
            dual_results = self.evaluate_dual_generator(dual_model)
            comparison_results['results']['dual_generator'] = dual_results
        
        # å¯¹æ¯”åˆ†æ
        if 'original' in comparison_results['results'] and 'dual_generator' in comparison_results['results']:
            comparison_analysis = self._analyze_comparison(
                comparison_results['results']['original'],
                comparison_results['results']['dual_generator']
            )
            comparison_results['comparison_analysis'] = comparison_analysis
        
        # ä¿å­˜ç»“æœ
        self._save_results(comparison_results)
        
        return comparison_results
    
    def _analyze_comparison(self, original_results: Dict, dual_results: Dict) -> Dict[str, any]:
        """åˆ†æå¯¹æ¯”ç»“æœ"""
        print("ğŸ” åˆ†æå¯¹æ¯”ç»“æœ...")
        
        orig_metrics = original_results['metrics']
        dual_metrics = dual_results['metrics']
        
        # è®¡ç®—æ”¹è¿›åº¦
        improvements = {}
        key_metrics = ['kl_divergence', 'earth_mover_distance', 'mse', 'mae']
        
        for metric in key_metrics:
            if metric in orig_metrics and metric in dual_metrics:
                orig_val = orig_metrics[metric]
                dual_val = dual_metrics[metric]
                
                if orig_val != 0:
                    improvement = (orig_val - dual_val) / orig_val * 100
                    improvements[f'{metric}_improvement_percent'] = improvement
        
        # æ€§èƒ½å¯¹æ¯”
        orig_time = original_results['performance']['avg_inference_time_per_sample']
        dual_time = dual_results['performance']['avg_inference_time_per_sample']
        
        time_ratio = dual_time / orig_time if orig_time != 0 else float('inf')
        
        # Mayo-Lewiså¯¹æ¯”åˆ†æ
        orig_mayo = original_results['mayo_lewis_comparison']
        dual_mayo = dual_results['mayo_lewis_comparison']
        
        mayo_analysis = {}
        for key in ['kl_improvement_percent', 'emd_improvement_percent']:
            if key in orig_mayo and key in dual_mayo:
                mayo_analysis[f'original_{key}'] = orig_mayo[key]
                mayo_analysis[f'dual_{key}'] = dual_mayo[key]
                mayo_analysis[f'{key}_difference'] = dual_mayo[key] - orig_mayo[key]
        
        analysis = {
            'metric_improvements': improvements,
            'performance_comparison': {
                'original_inference_time': orig_time,
                'dual_inference_time': dual_time,
                'time_ratio': time_ratio,
                'dual_is_faster': time_ratio < 1.0
            },
            'mayo_lewis_analysis': mayo_analysis,
            'summary': self._generate_summary(improvements, time_ratio, mayo_analysis)
        }
        
        return analysis
    
    def _generate_summary(self, improvements: Dict, time_ratio: float, mayo_analysis: Dict) -> str:
        """ç”Ÿæˆå¯¹æ¯”æ‘˜è¦"""
        summary_lines = ["=== PolyGenå¯¹æ¯”å®éªŒæ‘˜è¦ ==="]
        
        # æ€§èƒ½æ”¹è¿›
        kl_improvement = improvements.get('kl_divergence_improvement_percent', 0)
        emd_improvement = improvements.get('earth_mover_distance_improvement_percent', 0)
        
        if kl_improvement > 0:
            summary_lines.append(f"âœ… åŒç”Ÿæˆå™¨KLæ•£åº¦æ”¹è¿›: {kl_improvement:.2f}%")
        else:
            summary_lines.append(f"âŒ åŒç”Ÿæˆå™¨KLæ•£åº¦ä¸‹é™: {-kl_improvement:.2f}%")
        
        if emd_improvement > 0:
            summary_lines.append(f"âœ… åŒç”Ÿæˆå™¨EMDæ”¹è¿›: {emd_improvement:.2f}%")
        else:
            summary_lines.append(f"âŒ åŒç”Ÿæˆå™¨EMDä¸‹é™: {-emd_improvement:.2f}%")
        
        # æ¨ç†æ—¶é—´
        if time_ratio < 1.0:
            summary_lines.append(f"âš¡ åŒç”Ÿæˆå™¨æ¨ç†é€Ÿåº¦æå‡: {(1/time_ratio - 1)*100:.1f}%")
        else:
            summary_lines.append(f"ğŸŒ åŒç”Ÿæˆå™¨æ¨ç†é€Ÿåº¦ä¸‹é™: {(time_ratio - 1)*100:.1f}%")
        
        # Mayo-Lewiså¯¹æ¯”
        dual_mayo_kl = mayo_analysis.get('dual_kl_improvement_percent', 0)
        orig_mayo_kl = mayo_analysis.get('original_kl_improvement_percent', 0)
        
        summary_lines.append(f"ğŸ“ åŸå§‹æ¨¡å‹ vs Mayo-Lewis: {orig_mayo_kl:.2f}% KLæ”¹è¿›")
        summary_lines.append(f"ğŸ”„ åŒç”Ÿæˆå™¨ vs Mayo-Lewis: {dual_mayo_kl:.2f}% KLæ”¹è¿›")
        
        return "\n".join(summary_lines)
    
    def _save_results(self, results: Dict[str, any]):
        """ä¿å­˜å¯¹æ¯”ç»“æœ"""
        print("ğŸ’¾ ä¿å­˜å¯¹æ¯”ç»“æœ...")
        
        # ä¿å­˜JSONç»“æœï¼ˆç§»é™¤numpyæ•°ç»„ï¼‰
        json_results = {}
        for key, value in results.items():
            if key == 'results':
                json_results[key] = {}
                for model_name, model_results in value.items():
                    json_results[key][model_name] = {
                        k: v for k, v in model_results.items() 
                        if k not in ['predictions', 'targets', 'theoretical', 'residual_corrected']
                    }
            else:
                json_results[key] = value
        
        with open(self.output_dir / "comparison_results.json", 'w') as f:
            json.dump(json_results, f, indent=2, default=str)
        
        # ä¿å­˜numpyæ•°ç»„
        if 'results' in results:
            for model_name, model_results in results['results'].items():
                model_dir = self.output_dir / model_name
                model_dir.mkdir(exist_ok=True)
                
                for array_name in ['predictions', 'targets', 'theoretical', 'residual_corrected']:
                    if array_name in model_results:
                        np.save(model_dir / f"{array_name}.npy", model_results[array_name])
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")


def create_benchmark_config() -> BenchmarkConfig:
    """åˆ›å»ºåŸºå‡†æµ‹è¯•é…ç½®"""
    return BenchmarkConfig(
        csv_path="PolyGen-F06C/data/copolymer.csv",
        max_samples=500,  # é™åˆ¶æ ·æœ¬æ•°ç”¨äºå¿«é€Ÿæµ‹è¯•
        bins=50,
        batch_size=8,
        num_inference_steps=50,
        output_dir="outputs/benchmark_comparison",
        # æ³¨æ„: éœ€è¦æä¾›å®é™…çš„æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        original_cond_ckpt=None,  # "path/to/original/condition_encoder.pt"
        original_diffusion_ckpt=None,  # "path/to/original/diffusion_model.pt"
        dual_model_ckpt=None  # "path/to/dual_generator/best_model.pt"
    )


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ PolyGenå¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºé…ç½®
    config = create_benchmark_config()
    
    # è¿è¡Œå¯¹æ¯”å®éªŒ
    comparison = PolyGenComparison(config)
    results = comparison.run_comparison()
    
    # æ˜¾ç¤ºæ‘˜è¦
    if 'comparison_analysis' in results:
        print("\n" + results['comparison_analysis']['summary'])
    
    print(f"\nâœ… å¯¹æ¯”å®éªŒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {config.output_dir}")


if __name__ == "__main__":
    main()
