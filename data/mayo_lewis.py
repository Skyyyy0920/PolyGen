#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import numpy as np
import torch
from typing import Dict, List, Union
from collections import Counter


class MayoLewisCalculator:
    """
    Mayo-Lewisç†è®ºç›´æ¥è®¡ç®—å™¨
    
    åŸºäºç»å…¸Mayo-Lewiså…±èšç†è®ºï¼Œä»èšåˆç‰©åºåˆ—ç»Ÿè®¡é‡
    ç›´æ¥è®¡ç®—ç†è®ºå—é•¿åº¦åˆ†å¸ƒ
    """
    
    def __init__(self, max_length: int = 50):
        self.max_length = max_length
    
    def extract_sequence_statistics(self, sequences: List[str]) -> Dict[str, float]:
        """
        ä»èšåˆç‰©åºåˆ—ä¸­ç›´æ¥æå–ç»Ÿè®¡é‡
        
        Args:
            sequences: èšåˆç‰©åºåˆ—åˆ—è¡¨ï¼Œå¦‚ ['AAABBB', 'BBAABB']
            
        Returns:
            ç»Ÿè®¡å‚æ•°å­—å…¸ï¼ŒåŒ…å«f_A, p_AA, p_BBç­‰
        """
        if not sequences:
            return self._get_default_params()
        
        # åˆå¹¶æ‰€æœ‰åºåˆ—
        all_monomers = ''.join(sequences)
        if not all_monomers:
            return self._get_default_params()
        
        # è®¡ç®—å•ä½“ç»„æˆ
        count_A = all_monomers.count('A')
        count_B = all_monomers.count('B')
        total_monomers = len(all_monomers)
        
        f_A = count_A / total_monomers if total_monomers > 0 else 0.5
        f_B = 1 - f_A
        
        # è®¡ç®—è½¬æ¢æ¦‚ç‡
        pair_counts = Counter()
        for seq in sequences:
            if len(seq) >= 2:
                pairs = [seq[i:i+2] for i in range(len(seq)-1)]
                pair_counts.update(pairs)
        
        total_pairs = sum(pair_counts.values())
        if total_pairs == 0:
            return self._get_default_params()
        
        p_AA = pair_counts.get('AA', 0) / total_pairs
        p_BB = pair_counts.get('BB', 0) / total_pairs
        p_AB = pair_counts.get('AB', 0) / total_pairs
        p_BA = pair_counts.get('BA', 0) / total_pairs
        
        return {
            'f_A': f_A,
            'f_B': f_B,
            'p_AA': p_AA,
            'p_BB': p_BB,
            'p_AB': p_AB,
            'p_BA': p_BA,
            'total_monomers': total_monomers,
            'total_pairs': total_pairs
        }
    
    def _get_default_params(self) -> Dict[str, float]:
        """è¿”å›é»˜è®¤å‚æ•°"""
        return {
            'f_A': 0.5, 'f_B': 0.5,
            'p_AA': 0.3, 'p_BB': 0.3,
            'p_AB': 0.2, 'p_BA': 0.2,
            'total_monomers': 0, 'total_pairs': 0
        }
    
    def calculate_reactivity_ratios(self, params: Dict[str, float]) -> Dict[str, float]:
        """
        æ ¹æ®Mayo-Lewisç†è®ºä¼°è®¡ååº”æ€§æ¯”
        
        Args:
            params: åºåˆ—ç»Ÿè®¡å‚æ•°
            
        Returns:
            ååº”æ€§æ¯” r_A, r_B
        """
        f_A = params['f_A']
        f_B = params['f_B']
        p_AA = params['p_AA']
        p_BB = params['p_BB']
        
        # è®¡ç®—äº¤å‰è½¬æ¢æ¦‚ç‡
        p_AB = 1 - p_AA - p_BB
        p_AB = max(0.01, min(0.98, p_AB))  # æ•°å€¼ç¨³å®šæ€§
        
        # Mayo-Lewisååº”æ€§æ¯”ä¼°è®¡
        if p_AB > 0 and f_A > 0 and f_B > 0:
            r_A = (p_AA / (p_AB / 2)) * (f_B / f_A)
            r_B = (p_BB / (p_AB / 2)) * (f_A / f_B)
        else:
            r_A = r_B = 1.0
        
        # ç¡®ä¿ååº”æ€§æ¯”åœ¨åˆç†èŒƒå›´å†…
        r_A = max(0.01, min(10.0, r_A))
        r_B = max(0.01, min(10.0, r_B))
        
        return {'r_A': r_A, 'r_B': r_B, 'p_AB_calc': p_AB}
    
    def calculate_continuation_probabilities(self, params: Dict[str, float], 
                                           reactivity_ratios: Dict[str, float]) -> Dict[str, float]:
        """
        è®¡ç®—å—è¿ç»­æ¦‚ç‡
        
        Args:
            params: åºåˆ—ç»Ÿè®¡å‚æ•°
            reactivity_ratios: ååº”æ€§æ¯”
            
        Returns:
            è¿ç»­æ¦‚ç‡ p_A_continue, p_B_continue
        """
        f_A = params['f_A']
        f_B = params['f_B']
        r_A = reactivity_ratios['r_A']
        r_B = reactivity_ratios['r_B']
        
        # Mayo-Lewisè¿ç»­æ¦‚ç‡å…¬å¼
        denominator_A = r_A * f_A + f_B
        denominator_B = r_B * f_B + f_A
        
        p_A_continue = (r_A * f_A / denominator_A) if denominator_A > 0 else 0
        p_B_continue = (r_B * f_B / denominator_B) if denominator_B > 0 else 0
        
        # æ•°å€¼ç¨³å®šæ€§
        p_A_continue = max(0, min(0.99, p_A_continue))
        p_B_continue = max(0, min(0.99, p_B_continue))
        
        return {
            'p_A_continue': p_A_continue,
            'p_B_continue': p_B_continue
        }
    
    def calculate_geometric_distribution(self, p_continue: float, max_length: int) -> np.ndarray:
        """
        è®¡ç®—å‡ ä½•åˆ†å¸ƒ
        
        Args:
            p_continue: è¿ç»­æ¦‚ç‡
            max_length: æœ€å¤§å—é•¿åº¦
            
        Returns:
            å‡ ä½•åˆ†å¸ƒæ¦‚ç‡æ•°ç»„
        """
        lengths = np.arange(1, max_length + 1)
        
        if p_continue > 0:
            # å‡ ä½•åˆ†å¸ƒï¼šP(X=k) = (1-p) * p^(k-1)
            probs = (1 - p_continue) * (p_continue ** (lengths - 1))
        else:
            # å¦‚æœè¿ç»­æ¦‚ç‡ä¸º0ï¼Œæ‰€æœ‰å—é•¿åº¦ä¸º1
            probs = np.zeros(max_length)
            probs[0] = 1.0
        
        return probs
    
    def calculate_theoretical_distribution(self, sequences: List[str]) -> np.ndarray:
        """
        è®¡ç®—Mayo-Lewisç†è®ºåˆ†å¸ƒ
        
        Args:
            sequences: èšåˆç‰©åºåˆ—åˆ—è¡¨
            
        Returns:
            ç†è®ºå—é•¿åº¦åˆ†å¸ƒ [max_length,]
        """
        # 1. æå–åºåˆ—ç»Ÿè®¡
        params = self.extract_sequence_statistics(sequences)
        
        # 2. è®¡ç®—ååº”æ€§æ¯”
        reactivity_ratios = self.calculate_reactivity_ratios(params)
        
        # 3. è®¡ç®—è¿ç»­æ¦‚ç‡
        continuation_probs = self.calculate_continuation_probabilities(params, reactivity_ratios)
        
        # 4. è®¡ç®—Aå’ŒBçš„å‡ ä½•åˆ†å¸ƒ
        p_A_dist = self.calculate_geometric_distribution(
            continuation_probs['p_A_continue'], self.max_length
        )
        p_B_dist = self.calculate_geometric_distribution(
            continuation_probs['p_B_continue'], self.max_length
        )
        
        # 5. æŒ‰ç»„æˆåŠ æƒç»„åˆ
        f_A = params['f_A']
        f_B = params['f_B']
        combined_dist = f_A * p_A_dist + f_B * p_B_dist
        
        # 6. å½’ä¸€åŒ–
        total = np.sum(combined_dist)
        if total > 0:
            combined_dist = combined_dist / total
        
        return combined_dist.astype(np.float32)
    
    def batch_calculate_distributions(self, sequences_batch: List[List[str]]) -> torch.Tensor:
        """
        æ‰¹é‡è®¡ç®—ç†è®ºåˆ†å¸ƒ
        
        Args:
            sequences_batch: æ‰¹é‡åºåˆ—ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåºåˆ—åˆ—è¡¨
            
        Returns:
            æ‰¹é‡ç†è®ºåˆ†å¸ƒ [batch_size, max_length]
        """
        distributions = []
        
        for sequences in sequences_batch:
            dist = self.calculate_theoretical_distribution(sequences)
            distributions.append(dist)
        
        return torch.tensor(np.stack(distributions), dtype=torch.float32)
    
    def get_detailed_analysis(self, sequences: List[str]) -> Dict:
        """
        è·å–è¯¦ç»†çš„Mayo-Lewisåˆ†æç»“æœ
        
        Args:
            sequences: èšåˆç‰©åºåˆ—åˆ—è¡¨
            
        Returns:
            è¯¦ç»†åˆ†æç»“æœ
        """
        params = self.extract_sequence_statistics(sequences)
        reactivity_ratios = self.calculate_reactivity_ratios(params)
        continuation_probs = self.calculate_continuation_probabilities(params, reactivity_ratios)
        theoretical_dist = self.calculate_theoretical_distribution(sequences)
        
        return {
            'sequence_statistics': params,
            'reactivity_ratios': reactivity_ratios,
            'continuation_probabilities': continuation_probs,
            'theoretical_distribution': theoretical_dist,
            'distribution_stats': {
                'peak_position': int(np.argmax(theoretical_dist)) + 1,
                'peak_value': float(np.max(theoretical_dist)),
                'mean_length': float(np.sum(theoretical_dist * np.arange(1, len(theoretical_dist) + 1))),
                'entropy': -float(np.sum(theoretical_dist * np.log(theoretical_dist + 1e-8)))
            }
        }


def validate_mayo_lewis_calculation():
    """éªŒè¯Mayo-Lewisè®¡ç®—çš„æ­£ç¡®æ€§"""
    print("ğŸ§ª éªŒè¯Mayo-Lewisè®¡ç®—å™¨...")
    
    calc = MayoLewisCalculator(max_length=20)
    
    # æµ‹è¯•ç”¨ä¾‹1ï¼šäº¤æ›¿å…±èšç‰©
    alternating_seq = ['ABABABABAB', 'BABABABABA']
    result1 = calc.get_detailed_analysis(alternating_seq)
    
    print(f"äº¤æ›¿å…±èšç‰©åˆ†æ:")
    print(f"  f_A: {result1['sequence_statistics']['f_A']:.3f}")
    print(f"  p_AA: {result1['sequence_statistics']['p_AA']:.3f}")
    print(f"  r_A: {result1['reactivity_ratios']['r_A']:.3f}")
    print(f"  å³°å€¼ä½ç½®: {result1['distribution_stats']['peak_position']}")
    print(f"  å¹³å‡å—é•¿åº¦: {result1['distribution_stats']['mean_length']:.2f}")
    
    # æµ‹è¯•ç”¨ä¾‹2ï¼šå—çŠ¶å…±èšç‰©
    block_seq = ['AAAAABBBBBB', 'BBBBBAAAAAA']
    result2 = calc.get_detailed_analysis(block_seq)
    
    print(f"\nå—çŠ¶å…±èšç‰©åˆ†æ:")
    print(f"  f_A: {result2['sequence_statistics']['f_A']:.3f}")
    print(f"  p_AA: {result2['sequence_statistics']['p_AA']:.3f}")
    print(f"  r_A: {result2['reactivity_ratios']['r_A']:.3f}")
    print(f"  å³°å€¼ä½ç½®: {result2['distribution_stats']['peak_position']}")
    print(f"  å¹³å‡å—é•¿åº¦: {result2['distribution_stats']['mean_length']:.2f}")
    
    print("âœ… Mayo-Lewisè®¡ç®—å™¨éªŒè¯å®Œæˆ!")


if __name__ == "__main__":
    validate_mayo_lewis_calculation()
